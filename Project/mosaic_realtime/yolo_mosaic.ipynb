{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7kP2mdNTAZD"
      },
      "source": [
        "# yolo ê¹ƒí—ˆë¸Œ clone, í•„ìš” íŒŒì¼ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC8lKCwDkBQw",
        "outputId": "3a5d0f4e-8084-4c1f-bf05-68abfbaf25c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15002, done.\u001b[K\n",
            "remote: Total 15002 (delta 0), reused 0 (delta 0), pack-reused 15002\u001b[K\n",
            "Receiving objects: 100% (15002/15002), 14.08 MiB | 9.97 MiB/s, done.\n",
            "Resolving deltas: 100% (10285/10285), done.\n",
            "/content/yolov5\n",
            "HEAD is now at fbe67e4 Fix `OMP_NUM_THREADS=1` for macOS (#8624)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.0/49.0 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  \n",
        "%cd yolov5\n",
        "!pip install -qr requirements.txt  \n",
        "!pip install -q roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSYu_HWi2NnX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, yaml, glob, torch\n",
        "from distutils.dir_util import copy_tree\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "from roboflow import Roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5HtYqZP21MF"
      },
      "source": [
        "# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwQCLbwZ2dQc",
        "outputId": "18f47a35-4354-4afd-e1d0-d4856d872f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov5\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in knife_dataset-2 to yolov5pytorch: 100% [55599519 / 55599519] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to knife_dataset-2 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4413/4413 [00:01<00:00, 3692.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Cigarette-detection-1 to yolov5pytorch: 100% [47714628 / 47714628] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to Cigarette-detection-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4548/4548 [00:01<00:00, 3239.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Face-Detection-20 to yolov5pytorch: 100% [54336606 / 54336606] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to Face-Detection-20 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2750/2750 [00:01<00:00, 2300.68it/s]\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5\n",
        "#ì¹¼ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
        "rf = Roboflow(api_key=\"krcQlWTnG5PUWdI1yzWt\")\n",
        "project = rf.workspace(\"augustus\").project(\"knife_dataset-kysbg\")\n",
        "dataset = project.version(2).download(\"yolov5\")\n",
        "#ë‹´ë°° ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
        "project = rf.workspace(\"cigarettesmokingdetection\").project(\"cigarette-detection-uyqvc\")\n",
        "dataset = project.version(1).download(\"yolov5\")\n",
        "\n",
        "#ì–¼êµ´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
        "project = rf.workspace(\"mohamed-traore-2ekkp\").project(\"face-detection-mik1i\")\n",
        "dataset = project.version(20).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9XvtsIv3s92"
      },
      "source": [
        "# train, val, test ë°ì´í„° ê²½ë¡œ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO8K-QraYxvz",
        "outputId": "483ce219-54bf-4d22-c8e9-e1b14974a02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: 2496\n",
            "To: 0\n"
          ]
        }
      ],
      "source": [
        "#ì˜®ê¸¸ ë°ì´í„°ì…‹ê³¼ ì˜®ê²¨ì§ˆ ìœ„ì¹˜ì˜ ë°ì´í„°ì…‹ ì´ë¦„\n",
        "from_data = 'Cigarette-detection-1'\n",
        "to_data = 'knife_dataset-2'\n",
        "\n",
        "#í•´ë‹¹ ë°ì´í„°ì…‹ì— íŠ¹ì • í´ë˜ìŠ¤ê°€ ëª‡ê°œ ìˆëŠ”ì§€ í™•ì¸\n",
        "\n",
        "to_class = '0'\n",
        "from_class = '2'\n",
        "\n",
        "train = glob.glob(f'/content/yolov5/{from_data}/train/labels/*.txt')\n",
        "valid = glob.glob(f'/content/yolov5/{from_data}/valid/labels/*.txt')\n",
        "test = glob.glob(f'/content/yolov5/{from_data}/test/labels/*.txt')\n",
        "count=0\n",
        "for file_path in train+valid+test:\n",
        "    with open(file_path,'r') as f:\n",
        "        lines = f.readlines()\n",
        "    for i in range(len(lines)):\n",
        "        if lines[i].find(to_class, 0,1) == 0:\n",
        "          count+= 1\n",
        "\n",
        "print('From:',count)\n",
        "\n",
        "train = glob.glob(f'/content/yolov5/{to_data}/train/labels/*.txt')\n",
        "valid = glob.glob(f'/content/yolov5/{to_data}/valid/labels/*.txt')\n",
        "test = glob.glob(f'/content/yolov5/{to_data}/test/labels/*.txt')\n",
        "count=0\n",
        "for file_path in train+valid+test:\n",
        "    with open(file_path,'r') as f:\n",
        "        lines = f.readlines()\n",
        "    for i in range(len(lines)):\n",
        "        if lines[i].find(from_class, 0,1) == 0:\n",
        "          count+= 1\n",
        "print('To:',count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NYAuA5Za2Nz"
      },
      "outputs": [],
      "source": [
        "#from dataì— ìˆëŠ” from_target_class ë²ˆí˜¸ë¥¼ to_target_classë¡œ ë³€ê²½\n",
        "\n",
        "#ë§Œì•½ ë³€ê²½í•´ì•¼í•  í´ë˜ìŠ¤ìˆ˜ê°€ ë§ë‹¤ë©´ ìœ„ì—ì„œë¶€í„° ì§„í–‰\n",
        "\n",
        "train = glob.glob(f'/content/yolov5/{from_data}/train/labels/*.txt')\n",
        "valid = glob.glob(f'/content/yolov5/{from_data}/valid/labels/*.txt')\n",
        "test = glob.glob(f'/content/yolov5/{from_data}/test/labels/*.txt')\n",
        "for file_path in train+valid+test:\n",
        "    with open(file_path,'r') as f:\n",
        "        lines = f.readlines()\n",
        "    s = ''\n",
        "    for i in range(len(lines)):\n",
        "        s += lines[i].replace(to_class,from_class,1) +'\\n' \n",
        "    with open(file_path,'w') as f:\n",
        "        f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLLK3zOodH_R"
      },
      "outputs": [],
      "source": [
        "# ì…€ í†µí•©\n",
        "copy_tree(f'/content/yolov5/{from_data}/',f'/content/yolov5/{to_data}/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sN6rKRk470I"
      },
      "source": [
        "# data.yaml íŒŒì¼ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0FTJLqhdkB3",
        "outputId": "757c07c8-f871-4047-ee04-2f32e9eb7dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "names: ['knife', 'face', 'smoking']\n",
            "nc: 3\n",
            "train: ./knife_dataset-2/train/images\n",
            "val: ./knife_dataset-2/valid/images\n",
            "test: ./knife_dataset-2/test/images\n"
          ]
        }
      ],
      "source": [
        "#ë°ì´í„°ë¥¼ í•©ì¹˜ê³  ë‚œ í›„ class ìˆ˜(nc) ê° classë³„ ì´ë¦„(names) ì„¤ì • \n",
        "dataset.location = '/content/yolov5/knife_dataset-2'\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUQEV_one2s7"
      },
      "outputs": [],
      "source": [
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = yaml.safe_load(stream)['nc']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGET1bvAgE4E",
        "outputId": "71bbf89c-39de-49ba-baab-e0a1b49739fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.67  # model depth multiple\n",
            "width_multiple: 0.75  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ],
      "source": [
        "#ëª¨ë¸ ì„¤ì •\n",
        "%cat /content/yolov5/models/yolov5m.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq-o8RyvgGPR"
      },
      "outputs": [],
      "source": [
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRjYwaJZgJnT"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5m.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCdqHHEh5iDl"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-cr4FQT5Dd8",
        "outputId": "d3b867bd-7439-4f18-fdcb-ed93f3d26c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/custom_yolov5m.yaml, data=/content/yolov5/knife_dataset-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=mo_yolov5m_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 436 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 ğŸš€ v6.1-306-gfbe67e4 Python-3.8.10 torch-1.13.1+cu116 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ğŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "custom_YOLOv5m summary: 283 layers, 7260488 parameters, 7260488 gradients, 16.9 GFLOPs\n",
            "\n",
            "Transferred 40/369 items from yolov5m.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight (no decay), 70 weight, 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/knife_dataset-2/train/labels.cache' images and labels... 4812 found, 0 missing, 231 empty, 0 corrupt: 100% 4812/4812 [00:00<?, ?it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/knife_dataset-2/valid/labels.cache' images and labels... 790 found, 0 missing, 57 empty, 0 corrupt: 100% 790/790 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/train/mo_yolov5m_results2/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.10 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/mo_yolov5m_results2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/9        0G   0.09907   0.01761   0.03609        27       416: 100% 151/151 [50:57<00:00, 20.25s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 13/13 [03:12<00:00, 14.79s/it]\n",
            "                 all        790       1066   0.000552      0.119   0.000399   8.84e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/9        0G   0.09581   0.01749   0.03469        58       416:  69% 104/151 [35:23<15:55, 20.34s/it]"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5/\n",
        "\n",
        "!python train.py --img 416 --batch 32 --epoch 10 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5m.yaml --weights yolov5m.pt --name mo_yolov5m_results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}